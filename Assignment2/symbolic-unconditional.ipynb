{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi numpy torch tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaTGck_N1Cfb",
        "outputId": "86517fff-0598-4377-dea7-c02d55721181"
      },
      "id": "MaTGck_N1Cfb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/5.6 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/5.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592286 sha256=10c2210975b72b72c22da7a5c1887ba5d0ccf21b52d4393ba3cc181ecacdc4de\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/95/ac/15ceaeb2823b04d8e638fd1495357adb8d26c00ccac9d7782e\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mido, pretty_midi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed mido-1.3.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pretty_midi-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7107157d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7107157d",
        "outputId": "a2d1b8da-0cf9-4b4e-fc7d-c7b7e6cf823f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Dir: /content\n",
            "Downloading MAESTRO Dataset...\n",
            "Download Complete\n",
            "Extracting...\n",
            "Extracted to:/content/maestro\n"
          ]
        }
      ],
      "source": [
        "# ========== Download and extract MAESTRO Dataset ==========\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "print(f\"Current Dir: {current_dir}\")\n",
        "\n",
        "url = \"https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\"\n",
        "zip_path = os.path.join(current_dir, \"maestro-v3.0.0-midi.zip\")\n",
        "extract_path = os.path.join(current_dir, \"maestro\")\n",
        "\n",
        "# Download\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Downloading MAESTRO Dataset...\")\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "    print(\"Download Complete\")\n",
        "\n",
        "# Extract\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Extracting...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Extracted to:{extract_path}\")\n",
        "else:\n",
        "    print(\"Dataset already exists\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "36049d58",
      "metadata": {
        "id": "36049d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5d8ef6-ebbe-43a2-9c7a-e2276074b8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102537\n"
          ]
        }
      ],
      "source": [
        "from pretty_midi import PrettyMIDI\n",
        "import numpy as np\n",
        "\n",
        "note_events = []\n",
        "midi_files = 0\n",
        "for root, _, files in os.walk(extract_path):\n",
        "    for fname in files:\n",
        "        if \"Recital1-3\" in fname and fname.endswith(\".midi\"):\n",
        "        # if fname.endswith(\".mid\"):\n",
        "            try:\n",
        "                midi_files += 1\n",
        "                midi = PrettyMIDI(os.path.join(root, fname))\n",
        "                for instrument in midi.instruments:\n",
        "                    if instrument.is_drum:\n",
        "                        continue\n",
        "                    for note in instrument.notes:\n",
        "                        pitch = note.pitch\n",
        "                        velocity = note.velocity\n",
        "                        start = note.start\n",
        "                        end = note.end\n",
        "                        duration = end - start\n",
        "                        note_events.append((pitch, velocity, start, duration))\n",
        "            except Exception as e:\n",
        "                print(f\"Skip {fname}，Error: {e}\")\n",
        "\n",
        "# Sort by start time\n",
        "note_events.sort(key=lambda x: x[2])\n",
        "print(len(note_events))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Gather unique pitches and velocities\n",
        "pitches = sorted({evt[0] for evt in note_events})\n",
        "velocities = sorted({evt[1] for evt in note_events})\n",
        "\n",
        "# 4. Quantize durations to 0.05s bins and count unique\n",
        "quantized_durations = [round(evt[3]*20) / 20 for evt in note_events]\n",
        "unique_durations = sorted(set(quantized_durations))\n",
        "\n",
        "# 5. Display statistics\n",
        "print(f\"Total MIDI files        : {midi_files}\")\n",
        "print(f\"Total note events       : {len(note_events)}\")\n",
        "print(f\"Unique pitch values     : {len(pitches)}\")\n",
        "print(f\"Unique velocity bins    : {len(velocities)}\")\n",
        "print(f\"Quantized durations     : {len(unique_durations)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaH-WH70HgUL",
        "outputId": "bc96ac3a-46a1-43fb-b87f-62bab3124af2"
      },
      "id": "CaH-WH70HgUL",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MIDI files        : 1276\n",
            "Total note events       : 7040164\n",
            "Unique pitch values     : 88\n",
            "Unique velocity bins    : 126\n",
            "Quantized durations     : 367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f6dc0765",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6dc0765",
        "outputId": "e241c66e-cadb-48ec-c15e-f9c89710426e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pitch classes: 88, velocity classes: 121, duration classes: 165\n"
          ]
        }
      ],
      "source": [
        "pitches = sorted(set(n[0] for n in note_events))\n",
        "velocities = sorted(set(n[1] for n in note_events))\n",
        "# durations = sorted(set(round(n[3], 2) for n in note_events))\n",
        "dur_quantized = [round(n[3] * 20) / 20 for n in note_events]\n",
        "durations = sorted({d for d in dur_quantized})\n",
        "\n",
        "pitch2id = {p: i for i, p in enumerate(pitches)}\n",
        "vel2id = {v: i for i, v in enumerate(velocities)}\n",
        "dur2id = {d: i for i, d in enumerate(durations)}\n",
        "id2pitch = {i: p for p, i in pitch2id.items()}\n",
        "id2vel = {i: v for v, i in vel2id.items()}\n",
        "id2dur = {i: d for d, i in dur2id.items()}\n",
        "\n",
        "print(f\"pitch classes: {len(pitches)}, velocity classes: {len(velocities)}, duration classes: {len(durations)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "baec8de5",
      "metadata": {
        "id": "baec8de5"
      },
      "outputs": [],
      "source": [
        "seq_len = 128\n",
        "X, y = [], []\n",
        "\n",
        "# note_ids = [(pitch2id[n[0]], vel2id[n[1]], dur2id[round(n[3], 2)]) for n in note_events]\n",
        "note_ids = [(pitch2id[n[0]], vel2id[n[1]], dur2id[round(n[3] * 20) / 20]) for n in note_events]\n",
        "\n",
        "for i in range(len(note_ids) - seq_len):\n",
        "    X.append(note_ids[i:i+seq_len])\n",
        "    y.append(note_ids[i+seq_len])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cc2c88c6",
      "metadata": {
        "id": "cc2c88c6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PolyBiLSTM(nn.Module):\n",
        "    def __init__(self, pitch_size, vel_size, dur_size, embed_dim=128, hidden=256, num_layers=2):\n",
        "        super(PolyBiLSTM, self).__init__()\n",
        "        self.pitch_emb = nn.Embedding(pitch_size, embed_dim)\n",
        "        self.vel_emb = nn.Embedding(vel_size, embed_dim)\n",
        "        self.dur_emb = nn.Embedding(dur_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim * 3, hidden, num_layers=num_layers,\n",
        "                   batch_first=True, bidirectional=True, dropout=0.2)\n",
        "        self.pitch_out = nn.Linear(hidden * 2, pitch_size)\n",
        "        self.vel_out = nn.Linear(hidden * 2, vel_size)\n",
        "        self.dur_out = nn.Linear(hidden * 2, dur_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pitch, vel, dur = x[:,:,0], x[:,:,1], x[:,:,2]\n",
        "        p = self.pitch_emb(pitch)\n",
        "        v = self.vel_emb(vel)\n",
        "        d = self.dur_emb(dur)\n",
        "        x_cat = torch.cat([p, v, d], dim=-1)\n",
        "        _, (h, _) = self.lstm(x_cat)\n",
        "        # h = h[-1]\n",
        "        h = torch.cat((h[-2], h[-1]), dim=1)\n",
        "        return self.pitch_out(h), self.vel_out(h), self.dur_out(h)\n",
        "\n",
        "class PolyTransformer(nn.Module):\n",
        "    def __init__(self, pitch_size, vel_size, dur_size, embed_dim=128, nhead=8, num_layers=4, dim_feedforward=512, dropout=0.1):\n",
        "        super(PolyTransformer, self).__init__()\n",
        "        self.pitch_emb = nn.Embedding(pitch_size, embed_dim)\n",
        "        self.vel_emb = nn.Embedding(vel_size, embed_dim)\n",
        "        self.dur_emb = nn.Embedding(dur_size, embed_dim)\n",
        "        self.pos_emb = nn.Parameter(torch.randn(1, 512, embed_dim * 3))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim * 3, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.pitch_out = nn.Linear(embed_dim * 3, pitch_size)\n",
        "        self.vel_out = nn.Linear(embed_dim * 3, vel_size)\n",
        "        self.dur_out = nn.Linear(embed_dim * 3, dur_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pitch, vel, dur = x[:, :, 0], x[:, :, 1], x[:, :, 2]\n",
        "        p = self.pitch_emb(pitch)\n",
        "        v = self.vel_emb(vel)\n",
        "        d = self.dur_emb(dur)\n",
        "        x_cat = torch.cat([p, v, d], dim=-1)\n",
        "\n",
        "        seq_len = x_cat.size(1)\n",
        "        pos_emb = self.pos_emb[:, :seq_len, :]\n",
        "        x_cat = x_cat + pos_emb\n",
        "\n",
        "        x_cat = x_cat.transpose(0, 1)\n",
        "        h = self.transformer(x_cat)\n",
        "        h = h[-1]\n",
        "\n",
        "        return self.pitch_out(h), self.vel_out(h), self.dur_out(h)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f9481b05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9481b05",
        "outputId": "51a36eff-1f3e-4e56-be6e-bd6dc8a9404c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Avg Loss: 10.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Avg Loss: 10.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Avg Loss: 10.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Avg Loss: 10.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Avg Loss: 9.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Avg Loss: 9.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Avg Loss: 9.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Avg Loss: 9.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Avg Loss: 9.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Avg Loss: 9.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Avg Loss: 8.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Avg Loss: 8.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Avg Loss: 8.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Avg Loss: 8.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Avg Loss: 8.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# ========== Train ==========\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.long)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PolyBiLSTM(len(pitch2id), len(vel2id), len(dur2id)).to(device)\n",
        "# model = PolyTransformer(len(pitch2id), len(vel2id), len(dur2id)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
        "    for xb, yb in loop:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        out_p, out_v, out_d = model(xb)\n",
        "        loss = criterion(out_p, yb[:,0]) + criterion(out_v, yb[:,1]) + criterion(out_d, yb[:,2])\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch+1}, Avg Loss: {avg_loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = X.shape[0]\n",
        "train_end = int(0.8 * num_samples)\n",
        "val_end   = int(0.9 * num_samples)\n",
        "\n",
        "X_train, y_train = X[:train_end], y[:train_end]\n",
        "X_val,   y_val   = X[train_end:val_end], y[train_end:val_end]\n",
        "X_test,  y_test  = X[val_end:], y[val_end:]\n",
        "\n",
        "# Create TensorDatasets + DataLoaders\n",
        "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "val_ds   = TensorDataset(torch.tensor(X_val),   torch.tensor(y_val))\n",
        "test_ds  = TensorDataset(torch.tensor(X_test),  torch.tensor(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluation loop for test set\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = PolyBiLSTM(len(pitch2id), len(vel2id), len(dur2id)).to(device)\n",
        "model.eval()\n",
        "total_pitch, total_vel, total_dur = 0, 0, 0\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        p_logits, v_logits, d_logits = model(xb)\n",
        "        # Compute top-1 accuracy\n",
        "        p_pred = torch.argmax(p_logits, dim=1)\n",
        "        v_pred = torch.argmax(v_logits, dim=1)\n",
        "        d_pred = torch.argmax(d_logits, dim=1)\n",
        "        total_pitch += (p_pred == yb[:,0]).sum().item()\n",
        "        total_vel   += (v_pred == yb[:,1]).sum().item()\n",
        "        total_dur   += (d_pred == yb[:,2]).sum().item()\n",
        "        count += xb.size(0)\n",
        "\n",
        "pitch_acc = total_pitch / count\n",
        "vel_acc   = total_vel   / count\n",
        "dur_acc   = total_dur   / count\n",
        "\n",
        "print(f\"Test Pitch Acc: {pitch_acc:.3f}, Vel Acc: {vel_acc:.3f}, Dur Acc: {dur_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTezzPdbItCU",
        "outputId": "1d96c3ed-ee82-4650-caf2-4c778d946923"
      },
      "id": "JTezzPdbItCU",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Pitch Acc: 0.462, Vel Acc: 0.365, Dur Acc: 0.594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Compute Most-Frequent Baseline from training labels ---\n",
        "# Extract train labels as NumPy arrays for convenience\n",
        "y_train_np = np.array(y_train)  # shape (N_train, 3)\n",
        "pitch_counts = np.bincount(y_train_np[:, 0])\n",
        "vel_counts   = np.bincount(y_train_np[:, 1])\n",
        "dur_counts   = np.bincount(y_train_np[:, 2])\n",
        "\n",
        "# Find the most frequent ID in each category\n",
        "mf_pitch = int(np.argmax(pitch_counts))\n",
        "mf_vel   = int(np.argmax(vel_counts))\n",
        "mf_dur   = int(np.argmax(dur_counts))\n",
        "\n",
        "print(f\"Most frequent pitch_id = {mf_pitch}, vel_id = {mf_vel}, dur_id = {mf_dur}\")\n",
        "\n",
        "# Evaluate Most-Frequent baseline on test set\n",
        "total_mf_pitch, total_mf_vel, total_mf_dur = 0, 0, 0\n",
        "count = 0\n",
        "\n",
        "for xb, yb in test_loader:\n",
        "    yb = yb.numpy()  # (batch_size, 3)\n",
        "    batch_size = yb.shape[0]\n",
        "    # Create arrays of most frequent predictions\n",
        "    mf_pitch_preds = np.full(batch_size, mf_pitch, dtype=int)\n",
        "    mf_vel_preds   = np.full(batch_size, mf_vel,   dtype=int)\n",
        "    mf_dur_preds   = np.full(batch_size, mf_dur,   dtype=int)\n",
        "    # Compare to ground truth\n",
        "    total_mf_pitch += (mf_pitch_preds == yb[:, 0]).sum()\n",
        "    total_mf_vel   += (mf_vel_preds   == yb[:, 1]).sum()\n",
        "    total_mf_dur   += (mf_dur_preds   == yb[:, 2]).sum()\n",
        "    count += batch_size\n",
        "\n",
        "mf_pitch_acc = total_mf_pitch / count\n",
        "mf_vel_acc   = total_mf_vel / count\n",
        "mf_dur_acc   = total_mf_dur / count\n",
        "\n",
        "print(\"Most-Frequent Baseline Accuracies:\")\n",
        "print(f\"  Pitch Acc: {mf_pitch_acc:.3f}, Vel Acc: {mf_vel_acc:.3f}, Dur Acc: {mf_dur_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLuXvLOdSaeM",
        "outputId": "db7935b7-215b-427d-ed38-557a10bb7d80"
      },
      "id": "CLuXvLOdSaeM",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent pitch_id = 41, vel_id = 65, dur_id = 1\n",
            "Most-Frequent Baseline Accuracies:\n",
            "  Pitch Acc: 0.032, Vel Acc: 0.016, Dur Acc: 0.245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Evaluate Random (Uniform) Baseline on test set ---\n",
        "# We'll draw a single random prediction for each sample, uniformly over the respective vocab size\n",
        "pitch_vocab_size = len(pitch2id)\n",
        "vel_vocab_size   = len(vel2id)\n",
        "dur_vocab_size   = len(dur2id)\n",
        "\n",
        "total_rand_pitch, total_rand_vel, total_rand_dur = 0, 0, 0\n",
        "count = 0\n",
        "\n",
        "# Set a fixed seed for reproducibility\n",
        "random.seed(0)\n",
        "\n",
        "for xb, yb in test_loader:\n",
        "    yb = yb.numpy()  # (batch_size, 3)\n",
        "    batch_size = yb.shape[0]\n",
        "    # Generate random uniform predictions\n",
        "    rand_pitch_preds = np.random.randint(0, pitch_vocab_size, size=batch_size)\n",
        "    rand_vel_preds   = np.random.randint(0, vel_vocab_size,   size=batch_size)\n",
        "    rand_dur_preds   = np.random.randint(0, dur_vocab_size,   size=batch_size)\n",
        "    # Compare to ground truth\n",
        "    total_rand_pitch += (rand_pitch_preds == yb[:, 0]).sum()\n",
        "    total_rand_vel   += (rand_vel_preds   == yb[:, 1]).sum()\n",
        "    total_rand_dur   += (rand_dur_preds   == yb[:, 2]).sum()\n",
        "    count += batch_size\n",
        "\n",
        "rand_pitch_acc = total_rand_pitch / count\n",
        "rand_vel_acc   = total_rand_vel / count\n",
        "rand_dur_acc   = total_rand_dur / count\n",
        "\n",
        "print(\"Random Uniform Baseline Accuracies:\")\n",
        "print(f\"  Pitch Acc: {rand_pitch_acc:.3f}, Vel Acc: {rand_vel_acc:.3f}, Dur Acc: {rand_dur_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbFbymIjSib-",
        "outputId": "3ed7759d-aec5-4617-c93b-2fcaa64c8206"
      },
      "id": "gbFbymIjSib-",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Uniform Baseline Accuracies:\n",
            "  Pitch Acc: 0.013, Vel Acc: 0.009, Dur Acc: 0.006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b8c3bb9c",
      "metadata": {
        "id": "b8c3bb9c"
      },
      "outputs": [],
      "source": [
        "# Save model and dictionary\n",
        "import pickle\n",
        "\n",
        "torch.save(model.state_dict(), \"poly_lstm.pth\")\n",
        "with open(\"lstm_midi_maps.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\"pitch2id\": pitch2id, \"vel2id\": vel2id, \"dur2id\": dur2id,\n",
        "                 \"id2pitch\": id2pitch, \"id2vel\": id2vel, \"id2dur\": id2dur}, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and dictionary (if needed)\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(\"lstm_midi_maps (1).pkl\", \"rb\") as f:\n",
        "    midi_maps = pickle.load(f)\n",
        "\n",
        "pitch2id = midi_maps[\"pitch2id\"]\n",
        "vel2id = midi_maps[\"vel2id\"]\n",
        "dur2id = midi_maps[\"dur2id\"]\n",
        "id2pitch = midi_maps[\"id2pitch\"]\n",
        "id2vel = midi_maps[\"id2vel\"]\n",
        "id2dur = midi_maps[\"id2dur\"]\n",
        "\n",
        "# model = PolyBiLSTM(len(pitch2id), len(vel2id), len(dur2id)).to(device)\n",
        "model = PolyTransformer(len(pitch2id), len(vel2id), len(dur2id)).to(device)\n",
        "model.load_state_dict(torch.load(\"poly_lstm (1).pth\"))"
      ],
      "metadata": {
        "id": "uC9bdRGYlvUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f232fb68-2904-4b17-e1ab-36840d5672e2"
      },
      "id": "uC9bdRGYlvUn",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6e17492f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e17492f",
        "outputId": "2223e681-aa86-478f-c01c-57687e9170eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate complete：generated_lstm_polyphonic.mid\n"
          ]
        }
      ],
      "source": [
        "# ========== Generate music ==========\n",
        "from pretty_midi import PrettyMIDI, Instrument, Note\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def sample_from_logits(logits, temperature=1.0, top_k=None):\n",
        "    logits = logits / temperature\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    if top_k is not None and top_k > 0:\n",
        "        topk_vals, topk_idx = torch.topk(probs, top_k)\n",
        "        mask = torch.zeros_like(probs)\n",
        "        mask.scatter_(1, topk_idx, topk_vals)\n",
        "        probs = mask / mask.sum(dim=-1, keepdim=True)\n",
        "    sampled_id = torch.multinomial(probs, num_samples=1).item()\n",
        "    return sampled_id\n",
        "\n",
        "# baseMidi = PrettyMIDI('/content/maestro/maestro-v3.0.0/2018/MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--1.midi')\n",
        "baseMidi = PrettyMIDI('/content/maestro/maestro-v3.0.0/2018/MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--2.midi')\n",
        "baseNotes = []\n",
        "for instrument in baseMidi.instruments:\n",
        "    if instrument.is_drum:\n",
        "        continue\n",
        "    for note in instrument.notes:\n",
        "        pitch = note.pitch\n",
        "        velocity = note.velocity\n",
        "        start = note.start\n",
        "        end = note.end\n",
        "        duration = end - start\n",
        "        baseNotes.append((pitch, velocity, start, duration))\n",
        "\n",
        "basenote_ids = [(pitch2id[n[0]], vel2id[n[1]], dur2id[round(n[3] * 20) / 20]) for n in baseNotes]\n",
        "generated = basenote_ids[:seq_len]\n",
        "\n",
        "for _ in range(128):\n",
        "    inp = torch.tensor([generated[-seq_len:]], dtype=torch.long).to(device)\n",
        "    with torch.no_grad():\n",
        "        p, v, d = model(inp)\n",
        "    pitch = sample_from_logits(p, temperature=0.8, top_k=40)\n",
        "    vel   = sample_from_logits(v, temperature=0.8, top_k=None)\n",
        "    dur   = sample_from_logits(d, temperature=0.8, top_k=None)\n",
        "    generated.append([pitch, vel, dur])\n",
        "\n",
        "# Write into midi file\n",
        "start = 0.0\n",
        "notes = []\n",
        "for p, v, d in generated:\n",
        "    pitch = id2pitch[p]\n",
        "    velocity = id2vel[v]\n",
        "    duration = id2dur[d]\n",
        "    notes.append((pitch, velocity, start, start + duration))\n",
        "    start += duration\n",
        "\n",
        "midi = PrettyMIDI()\n",
        "piano = Instrument(program=0)\n",
        "for pitch, vel, s, e in notes:\n",
        "    piano.notes.append(Note(velocity=vel, pitch=pitch, start=s, end=e))\n",
        "midi.instruments.append(piano)\n",
        "midi.write(\"generated_lstm_polyphonic.mid\")\n",
        "print(\"Generate complete：generated_lstm_polyphonic.mid\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# --- 3. Compute Most-Frequent IDs from Training Set ---\n",
        "num_samples = X.shape[0]\n",
        "train_end = int(0.8 * num_samples)\n",
        "val_end   = int(0.9 * num_samples)\n",
        "\n",
        "X_train, y_train = X[:train_end], y[:train_end]\n",
        "X_val,   y_val   = X[train_end:val_end], y[train_end:val_end]\n",
        "X_test,  y_test  = X[val_end:], y[val_end:]\n",
        "\n",
        "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "val_ds   = TensorDataset(torch.tensor(X_val),   torch.tensor(y_val))\n",
        "test_ds  = TensorDataset(torch.tensor(X_test),  torch.tensor(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "y_train_np = np.array(y_train)  # shape (N_train, 3)\n",
        "mf_pitch = int(np.argmax(np.bincount(y_train_np[:, 0])))\n",
        "mf_vel   = int(np.argmax(np.bincount(y_train_np[:, 1])))\n",
        "mf_dur   = int(np.argmax(np.bincount(y_train_np[:, 2])))\n",
        "print(f\"Most-Frequent Baseline IDs → Pitch: {mf_pitch}, Vel: {mf_vel}, Dur: {mf_dur}\")\n",
        "\n",
        "# --- 4. Initialize Accumulators ---\n",
        "# Model metrics\n",
        "ce_pitch = nn.CrossEntropyLoss()\n",
        "ce_vel   = nn.CrossEntropyLoss()\n",
        "ce_dur   = nn.CrossEntropyLoss()\n",
        "\n",
        "total_ce_pitch = 0.0\n",
        "total_ce_vel   = 0.0\n",
        "total_ce_dur   = 0.0\n",
        "\n",
        "total_mse_pitch = 0.0\n",
        "total_mse_vel   = 0.0\n",
        "total_mse_dur   = 0.0\n",
        "\n",
        "total_mae_pitch = 0.0\n",
        "total_mae_vel   = 0.0\n",
        "total_mae_dur   = 0.0\n",
        "\n",
        "count = 0\n",
        "\n",
        "# Baseline accumulators\n",
        "mf_mse_pitch = 0.0\n",
        "mf_mse_vel   = 0.0\n",
        "mf_mse_dur   = 0.0\n",
        "\n",
        "mf_mae_pitch = 0.0\n",
        "mf_mae_vel   = 0.0\n",
        "mf_mae_dur   = 0.0\n",
        "\n",
        "rand_mse_pitch = 0.0\n",
        "rand_mse_vel   = 0.0\n",
        "rand_mse_dur   = 0.0\n",
        "\n",
        "rand_mae_pitch = 0.0\n",
        "rand_mae_vel   = 0.0\n",
        "rand_mae_dur   = 0.0\n",
        "\n",
        "pitch_vocab_size = len(pitch2id)\n",
        "vel_vocab_size   = len(vel2id)\n",
        "dur_vocab_size   = len(dur2id)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "random.seed(0)\n",
        "\n",
        "# --- 5. Iterate Over Test Set ---\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        batch_size = xb.size(0)\n",
        "\n",
        "        # ---- Model Predictions ----\n",
        "        p_logits, v_logits, d_logits = model(xb)\n",
        "\n",
        "        # Cross-Entropy Loss\n",
        "        loss_p = ce_pitch(p_logits, yb[:, 0])\n",
        "        loss_v = ce_vel(  v_logits, yb[:, 1])\n",
        "        loss_d = ce_dur(  d_logits, yb[:, 2])\n",
        "\n",
        "        total_ce_pitch += loss_p.item() * batch_size\n",
        "        total_ce_vel   += loss_v.item() * batch_size\n",
        "        total_ce_dur   += loss_d.item() * batch_size\n",
        "\n",
        "        # Predicted IDs\n",
        "        p_pred = torch.argmax(p_logits, dim=1)\n",
        "        v_pred = torch.argmax(v_logits, dim=1)\n",
        "        d_pred = torch.argmax(d_logits, dim=1)\n",
        "\n",
        "        # MSE & MAE for model\n",
        "        mse_p = (p_pred.float() - yb[:, 0].float()).pow(2).sum().item()\n",
        "        mse_v = (v_pred.float() - yb[:, 1].float()).pow(2).sum().item()\n",
        "        mse_d = (d_pred.float() - yb[:, 2].float()).pow(2).sum().item()\n",
        "\n",
        "        mae_p = torch.abs(p_pred.float() - yb[:, 0].float()).sum().item()\n",
        "        mae_v = torch.abs(v_pred.float() - yb[:, 1].float()).sum().item()\n",
        "        mae_d = torch.abs(d_pred.float() - yb[:, 2].float()).sum().item()\n",
        "\n",
        "        total_mse_pitch += mse_p\n",
        "        total_mse_vel   += mse_v\n",
        "        total_mse_dur   += mse_d\n",
        "\n",
        "        total_mae_pitch += mae_p\n",
        "        total_mae_vel   += mae_v\n",
        "        total_mae_dur   += mae_d\n",
        "\n",
        "        # ---- Most-Frequent Baseline ----\n",
        "        yb_np = yb.cpu().numpy()\n",
        "        # MSE\n",
        "        mf_mse_pitch += ((mf_pitch - yb_np[:, 0]) ** 2).sum()\n",
        "        mf_mse_vel   += ((mf_vel   - yb_np[:, 1]) ** 2).sum()\n",
        "        mf_mse_dur   += ((mf_dur   - yb_np[:, 2]) ** 2).sum()\n",
        "        # MAE\n",
        "        mf_mae_pitch += np.abs(mf_pitch - yb_np[:, 0]).sum()\n",
        "        mf_mae_vel   += np.abs(mf_vel   - yb_np[:, 1]).sum()\n",
        "        mf_mae_dur   += np.abs(mf_dur   - yb_np[:, 2]).sum()\n",
        "\n",
        "        # ---- Random Uniform Baseline ----\n",
        "        rand_p = np.random.randint(0, pitch_vocab_size,   size=batch_size)\n",
        "        rand_v = np.random.randint(0, vel_vocab_size,     size=batch_size)\n",
        "        rand_d = np.random.randint(0, dur_vocab_size,     size=batch_size)\n",
        "\n",
        "        # MSE\n",
        "        rand_mse_pitch += ((rand_p - yb_np[:, 0]) ** 2).sum()\n",
        "        rand_mse_vel   += ((rand_v - yb_np[:, 1]) ** 2).sum()\n",
        "        rand_mse_dur   += ((rand_d - yb_np[:, 2]) ** 2).sum()\n",
        "        # MAE\n",
        "        rand_mae_pitch += np.abs(rand_p - yb_np[:, 0]).sum()\n",
        "        rand_mae_vel   += np.abs(rand_v - yb_np[:, 1]).sum()\n",
        "        rand_mae_dur   += np.abs(rand_d - yb_np[:, 2]).sum()\n",
        "\n",
        "        count += batch_size\n",
        "\n",
        "# --- 6. Compute Model Metrics ---\n",
        "avg_ce_pitch = total_ce_pitch / count\n",
        "avg_ce_vel   = total_ce_vel   / count\n",
        "avg_ce_dur   = total_ce_dur   / count\n",
        "\n",
        "perplexity_pitch = math.exp(avg_ce_pitch)\n",
        "perplexity_vel   = math.exp(avg_ce_vel)\n",
        "perplexity_dur   = math.exp(avg_ce_dur)\n",
        "\n",
        "mse_pitch = total_mse_pitch / count\n",
        "mse_vel   = total_mse_vel   / count\n",
        "mse_dur   = total_mse_dur   / count\n",
        "\n",
        "mae_pitch = total_mae_pitch / count\n",
        "mae_vel   = total_mae_vel   / count\n",
        "mae_dur   = total_mae_dur   / count\n",
        "\n",
        "# --- 7. Compute Baseline Metrics ---\n",
        "mf_mse_pitch /= count\n",
        "mf_mse_vel   /= count\n",
        "mf_mse_dur   /= count\n",
        "\n",
        "mf_mae_pitch /= count\n",
        "mf_mae_vel   /= count\n",
        "mf_mae_dur   /= count\n",
        "\n",
        "rand_mse_pitch /= count\n",
        "rand_mse_vel   /= count\n",
        "rand_mse_dur   /= count\n",
        "\n",
        "rand_mae_pitch /= count\n",
        "rand_mae_vel   /= count\n",
        "rand_mae_dur   /= count\n",
        "\n",
        "# --- 8. Print Results ---\n",
        "print(\"===== Model (BiLSTM) Metrics =====\")\n",
        "print(f\"Cross-Entropy (Pitch): {avg_ce_pitch:.4f}, Perplexity: {perplexity_pitch:.2f}\")\n",
        "print(f\"Cross-Entropy (Vel):   {avg_ce_vel:.4f}, Perplexity: {perplexity_vel:.2f}\")\n",
        "print(f\"Cross-Entropy (Dur):   {avg_ce_dur:.4f}, Perplexity: {perplexity_dur:.2f}\\n\")\n",
        "\n",
        "print(f\"MSE (Pitch): {mse_pitch:.3f}, MAE (Pitch): {mae_pitch:.3f}\")\n",
        "print(f\"MSE (Vel):   {mse_vel:.3f},   MAE (Vel):   {mae_vel:.3f}\")\n",
        "print(f\"MSE (Dur):   {mse_dur:.3f},   MAE (Dur):   {mae_dur:.3f}\\n\")\n",
        "\n",
        "print(\"===== Most-Frequent Baseline Metrics =====\")\n",
        "print(f\"MSE (Pitch): {mf_mse_pitch:.3f}, MAE (Pitch): {mf_mae_pitch:.3f}\")\n",
        "print(f\"MSE (Vel):   {mf_mse_vel:.3f},   MAE (Vel):   {mf_mae_vel:.3f}\")\n",
        "print(f\"MSE (Dur):   {mf_mse_dur:.3f},   MAE (Dur):   {mf_mae_dur:.3f}\\n\")\n",
        "\n",
        "print(\"===== Random Uniform Baseline Metrics =====\")\n",
        "print(f\"MSE (Pitch): {rand_mse_pitch:.3f}, MAE (Pitch): {rand_mae_pitch:.3f}\")\n",
        "print(f\"MSE (Vel):   {rand_mse_vel:.3f},   MAE (Vel):   {rand_mae_vel:.3f}\")\n",
        "print(f\"MSE (Dur):   {rand_mse_dur:.3f},   MAE (Dur):   {rand_mae_dur:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naKe2AvFaI8K",
        "outputId": "40ed80e3-1d5b-4fee-e1f4-4334ceee24dd"
      },
      "id": "naKe2AvFaI8K",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most-Frequent Baseline IDs → Pitch: 41, Vel: 65, Dur: 1\n",
            "===== Model (BiLSTM) Metrics =====\n",
            "Cross-Entropy (Pitch): 4.0844, Perplexity: 59.40\n",
            "Cross-Entropy (Vel):   4.4245, Perplexity: 83.47\n",
            "Cross-Entropy (Dur):   2.3970, Perplexity: 10.99\n",
            "\n",
            "MSE (Pitch): 197.186, MAE (Pitch): 11.461\n",
            "MSE (Vel):   441.791,   MAE (Vel):   17.843\n",
            "MSE (Dur):   130.246,   MAE (Dur):   4.344\n",
            "\n",
            "===== Most-Frequent Baseline Metrics =====\n",
            "MSE (Pitch): 194.101, MAE (Pitch): 11.442\n",
            "MSE (Vel):   413.645,   MAE (Vel):   16.624\n",
            "MSE (Dur):   130.246,   MAE (Dur):   4.344\n",
            "\n",
            "===== Random Uniform Baseline Metrics =====\n",
            "MSE (Pitch): 830.302, MAE (Pitch): 24.104\n",
            "MSE (Vel):   1672.456,   MAE (Vel):   34.050\n",
            "MSE (Dur):   8185.461,   MAE (Dur):   77.149\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}